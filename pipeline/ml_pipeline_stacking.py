import numpy as np
import pandas as pd
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.linear_model import RidgeCV
from sklearn.ensemble import StackingRegressor
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from catboost import CatBoostRegressor
from lightgbm import LGBMRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_log_error
import json

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
train = pd.read_csv("data/train.csv")
test = pd.read_csv("data/test.csv")
train['Calories'] = np.log1p(train['Calories'])

# # ì¡°í•© í”¼ì²˜
# train['HR_Duration'] = train['Heart_Rate'] * train['Duration']
# train['BT_Duration'] = train['Body_Temp'] * train['Duration']
# test['HR_Duration'] = test['Heart_Rate'] * test['Duration']
# test['BT_Duration'] = test['Body_Temp'] * test['Duration']

# í”¼ì²˜ ë¶„ë¦¬
drop_cols = ['id', 'Calories']
numeric_feats = train.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical_feats = train.select_dtypes(include=['object']).columns.tolist()
numeric_feats = [col for col in numeric_feats if col not in drop_cols]
categorical_feats = [col for col in categorical_feats if col not in drop_cols]

# for feat in ['HR_Duration', 'BT_Duration']:
#     if feat not in numeric_feats:
#         numeric_feats.append(feat)

main_features = numeric_feats + categorical_feats

X = train[main_features]
y = train['Calories']
X_test = test[main_features]

# ì „ì²˜ë¦¬ê¸° ì •ì˜
numeric_transformer = Pipeline([('scaler', StandardScaler())])
categorical_transformer = Pipeline([('encoder', OneHotEncoder(handle_unknown='ignore'))])
preprocessor = ColumnTransformer([
    ('num', numeric_transformer, numeric_feats),
    ('cat', categorical_transformer, categorical_feats)
])

# ìµœì  íŒŒë¼ë¯¸í„° ë¡œë”©
with open("data/best_params_catboost.json") as f:
    best_params_cat = json.load(f)
best_params_cat["random_seed"] = 42
best_params_cat["logging_level"] = "Silent"

with open("data/best_params_lgb.json") as f:
    best_params_lgb = json.load(f)
best_params_lgb["random_state"] = 42

with open("data/best_params_xgb.json") as f:
    best_params_xgb = json.load(f)
best_params_xgb["random_state"] = 42

# ê°œë³„ ëª¨ë¸ ì •ì˜
estimators = [
    ('cat', CatBoostRegressor(**best_params_cat)),
    ('lgb', LGBMRegressor(**best_params_lgb)),
    ('xgb', XGBRegressor(**best_params_xgb))
]

# ë©”íƒ€ëª¨ë¸ ì •ì˜
final_estimator = RidgeCV(alphas=[0.1, 1.0, 10.0])

# ìŠ¤íƒœí‚¹ ëª¨ë¸ êµ¬ì„±
stacking_model = StackingRegressor(
    estimators=estimators,
    final_estimator=final_estimator,
    passthrough=False,
    cv=5,
    n_jobs=-1
)

# ì „ì²´ íŒŒì´í”„ë¼ì¸ êµ¬ì„±
model_pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('stack', stacking_model)
])

# í•™ìŠµ ë° ì˜ˆì¸¡
model_pipeline.fit(X, y)

y_pred_log = model_pipeline.predict(X)
y_pred = np.expm1(y_pred_log)
y_true = np.expm1(y)
rmsle = np.sqrt(mean_squared_log_error(y_true, y_pred))
print(f"\nğŸ“Š Stacking RMSLE (with StackingRegressor): {rmsle:.4f}")

# í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡ ë° ì œì¶œ
y_test_pred = np.expm1(model_pipeline.predict(X_test))
submission = pd.DataFrame({'id': test['id'], 'Calories': y_test_pred})
current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
submission.to_csv(f"submissions/submission_stacking_regressor_{current_time}.csv", index=False)
print("âœ… ì œì¶œ ì™„ë£Œ")
